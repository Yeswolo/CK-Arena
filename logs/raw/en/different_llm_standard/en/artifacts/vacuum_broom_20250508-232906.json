{
  "game_record": {
    "game_id": "20250508-232508",
    "timestamp": "2025-05-08T23:25:08.014245",
    "topic_category": "artifacts",
    "concept_pair": {
      "concept_a": "vacuum",
      "concept_b": "broom"
    },
    "judges": [
      {
        "id": "claude-3-7-sonnet-20250219",
        "version": ""
      },
      {
        "id": "gpt-4.1-2025-04-14",
        "version": ""
      }
    ],
    "players": [
      {
        "player_id": 1,
        "llm_id": "claude-3-5-haiku-20241022",
        "role": "civilian",
        "assigned_concept": "vacuum",
        "eliminated_in_voting_round": null,
        "is_winner": false
      },
      {
        "player_id": 2,
        "llm_id": "gpt-4o-2024-11-20",
        "role": "civilian",
        "assigned_concept": "vacuum",
        "eliminated_in_voting_round": 1,
        "is_winner": false
      },
      {
        "player_id": 3,
        "llm_id": "qwen2.5-72b",
        "role": "civilian",
        "assigned_concept": "vacuum",
        "eliminated_in_voting_round": -1,
        "is_winner": false
      },
      {
        "player_id": 4,
        "llm_id": "llama-3.3-70b-instruct",
        "role": "civilian",
        "assigned_concept": "vacuum",
        "eliminated_in_voting_round": 2,
        "is_winner": false
      },
      {
        "player_id": 5,
        "llm_id": "gemini-2.0-pro-exp",
        "role": "undercover",
        "assigned_concept": "broom",
        "eliminated_in_voting_round": null,
        "is_winner": true
      },
      {
        "player_id": 6,
        "llm_id": "deepseek-v3",
        "role": "undercover",
        "assigned_concept": "broom",
        "eliminated_in_voting_round": -1,
        "is_winner": true
      }
    ],
    "game_process": {
      "statements": [
        {
          "statement_id": 1,
          "player_id": 2,
          "llm_id": "gpt-4o-2024-11-20",
          "content": "A device often used for cleaning purposes.",
          "statement_round": 1,
          "metrics": {
            "judges_evaluations": [
              {
                "judge_id": "claude-3-7-sonnet-20250219",
                "metrics": {
                  "novelty_score": 1.0,
                  "relevance_score": 0.4,
                  "reasonableness_score": 1.0
                }
              },
              {
                "judge_id": "gpt-4.1-2025-04-14",
                "metrics": {
                  "novelty_score": 1.0,
                  "relevance_score": 0.4,
                  "reasonableness_score": 1.0
                }
              }
            ],
            "judges_stats": {
              "novelty_score_mean": 1.0,
              "novelty_score_variance": 0.0,
              "novelty_score_all_values": {
                "claude-3-7-sonnet-20250219": 1.0,
                "gpt-4.1-2025-04-14": 1.0
              },
              "relevance_score_mean": 0.4,
              "relevance_score_variance": 0.0,
              "relevance_score_all_values": {
                "claude-3-7-sonnet-20250219": 0.4,
                "gpt-4.1-2025-04-14": 0.4
              },
              "reasonableness_score_mean": 1.0,
              "reasonableness_score_variance": 0.0,
              "reasonableness_score_all_values": {
                "claude-3-7-sonnet-20250219": 1.0,
                "gpt-4.1-2025-04-14": 1.0
              }
            }
          }
        },
        {
          "statement_id": 2,
          "player_id": 5,
          "llm_id": "gemini-2.0-pro-exp",
          "content": "It often involves a handle and bristles.",
          "statement_round": 1,
          "metrics": {
            "judges_evaluations": [
              {
                "judge_id": "claude-3-7-sonnet-20250219",
                "metrics": {
                  "novelty_score": 0.8,
                  "relevance_score": 0.8,
                  "reasonableness_score": 1.0
                }
              },
              {
                "judge_id": "gpt-4.1-2025-04-14",
                "metrics": {
                  "novelty_score": 0.6,
                  "relevance_score": 0.8,
                  "reasonableness_score": 1.0
                }
              }
            ],
            "judges_stats": {
              "novelty_score_mean": 0.7,
              "novelty_score_variance": 0.010000000000000005,
              "novelty_score_all_values": {
                "claude-3-7-sonnet-20250219": 0.8,
                "gpt-4.1-2025-04-14": 0.6
              },
              "relevance_score_mean": 0.8,
              "relevance_score_variance": 0.0,
              "relevance_score_all_values": {
                "claude-3-7-sonnet-20250219": 0.8,
                "gpt-4.1-2025-04-14": 0.8
              },
              "reasonableness_score_mean": 1.0,
              "reasonableness_score_variance": 0.0,
              "reasonableness_score_all_values": {
                "claude-3-7-sonnet-20250219": 1.0,
                "gpt-4.1-2025-04-14": 1.0
              }
            }
          }
        },
        {
          "statement_id": 3,
          "player_id": 4,
          "llm_id": "llama-3.3-70b-instruct",
          "content": "It is typically used to pick up dirt and dust from floors and surfaces.",
          "statement_round": 1,
          "metrics": {
            "judges_evaluations": [
              {
                "judge_id": "claude-3-7-sonnet-20250219",
                "metrics": {
                  "novelty_score": 0.8,
                  "relevance_score": 0.6,
                  "reasonableness_score": 1.0
                }
              },
              {
                "judge_id": "gpt-4.1-2025-04-14",
                "metrics": {
                  "novelty_score": 0.6,
                  "relevance_score": 0.6,
                  "reasonableness_score": 1.0
                }
              }
            ],
            "judges_stats": {
              "novelty_score_mean": 0.7,
              "novelty_score_variance": 0.010000000000000005,
              "novelty_score_all_values": {
                "claude-3-7-sonnet-20250219": 0.8,
                "gpt-4.1-2025-04-14": 0.6
              },
              "relevance_score_mean": 0.6,
              "relevance_score_variance": 0.0,
              "relevance_score_all_values": {
                "claude-3-7-sonnet-20250219": 0.6,
                "gpt-4.1-2025-04-14": 0.6
              },
              "reasonableness_score_mean": 1.0,
              "reasonableness_score_variance": 0.0,
              "reasonableness_score_all_values": {
                "claude-3-7-sonnet-20250219": 1.0,
                "gpt-4.1-2025-04-14": 1.0
              }
            }
          }
        },
        {
          "statement_id": 4,
          "player_id": 3,
          "llm_id": "qwen2.5-72b",
          "content": "A tool commonly found in households for maintaining cleanliness.",
          "statement_round": 1,
          "metrics": {
            "judges_evaluations": [
              {
                "judge_id": "claude-3-7-sonnet-20250219",
                "metrics": {
                  "novelty_score": 0.2,
                  "relevance_score": 0.2,
                  "reasonableness_score": 1.0
                }
              },
              {
                "judge_id": "gpt-4.1-2025-04-14",
                "metrics": {
                  "novelty_score": 0.2,
                  "relevance_score": 0.4,
                  "reasonableness_score": 1.0
                }
              }
            ],
            "judges_stats": {
              "novelty_score_mean": 0.2,
              "novelty_score_variance": 0.0,
              "novelty_score_all_values": {
                "claude-3-7-sonnet-20250219": 0.2,
                "gpt-4.1-2025-04-14": 0.2
              },
              "relevance_score_mean": 0.30000000000000004,
              "relevance_score_variance": 0.010000000000000002,
              "relevance_score_all_values": {
                "claude-3-7-sonnet-20250219": 0.2,
                "gpt-4.1-2025-04-14": 0.4
              },
              "reasonableness_score_mean": 1.0,
              "reasonableness_score_variance": 0.0,
              "reasonableness_score_all_values": {
                "claude-3-7-sonnet-20250219": 1.0,
                "gpt-4.1-2025-04-14": 1.0
              }
            }
          }
        },
        {
          "statement_id": 5,
          "player_id": 6,
          "llm_id": "deepseek-v3",
          "content": "NONE",
          "statement_round": 1,
          "metrics": {
            "judges_evaluations": [
              {
                "judge_id": "claude-3-7-sonnet-20250219",
                "metrics": {
                  "novelty_score": 0,
                  "relevance_score": 0,
                  "reasonableness_score": 0
                }
              },
              {
                "judge_id": "gpt-4.1-2025-04-14",
                "metrics": {
                  "novelty_score": 1.0,
                  "relevance_score": 0,
                  "reasonableness_score": 0
                }
              }
            ],
            "judges_stats": {
              "novelty_score_mean": 0.5,
              "novelty_score_variance": 0.25,
              "novelty_score_all_values": {
                "claude-3-7-sonnet-20250219": 0,
                "gpt-4.1-2025-04-14": 1.0
              },
              "relevance_score_mean": 0.0,
              "relevance_score_variance": 0.0,
              "relevance_score_all_values": {
                "claude-3-7-sonnet-20250219": 0,
                "gpt-4.1-2025-04-14": 0
              },
              "reasonableness_score_mean": 0.0,
              "reasonableness_score_variance": 0.0,
              "reasonableness_score_all_values": {
                "claude-3-7-sonnet-20250219": 0,
                "gpt-4.1-2025-04-14": 0
              }
            }
          }
        },
        {
          "statement_id": 6,
          "player_id": 1,
          "llm_id": "claude-3-5-haiku-20241022",
          "content": "Operates using suction power to collect unwanted particles.",
          "statement_round": 1,
          "metrics": {
            "judges_evaluations": [
              {
                "judge_id": "claude-3-7-sonnet-20250219",
                "metrics": {
                  "novelty_score": 1.0,
                  "relevance_score": 1.0,
                  "reasonableness_score": 1.0
                }
              },
              {
                "judge_id": "gpt-4.1-2025-04-14",
                "metrics": {
                  "novelty_score": 1.0,
                  "relevance_score": 1.0,
                  "reasonableness_score": 1.0
                }
              }
            ],
            "judges_stats": {
              "novelty_score_mean": 1.0,
              "novelty_score_variance": 0.0,
              "novelty_score_all_values": {
                "claude-3-7-sonnet-20250219": 1.0,
                "gpt-4.1-2025-04-14": 1.0
              },
              "relevance_score_mean": 1.0,
              "relevance_score_variance": 0.0,
              "relevance_score_all_values": {
                "claude-3-7-sonnet-20250219": 1.0,
                "gpt-4.1-2025-04-14": 1.0
              },
              "reasonableness_score_mean": 1.0,
              "reasonableness_score_variance": 0.0,
              "reasonableness_score_all_values": {
                "claude-3-7-sonnet-20250219": 1.0,
                "gpt-4.1-2025-04-14": 1.0
              }
            }
          }
        },
        {
          "statement_id": 7,
          "player_id": 5,
          "llm_id": "gemini-2.0-pro-exp",
          "content": "It helps maintain a tidy environment in homes.",
          "statement_round": 2,
          "metrics": {
            "judges_evaluations": [
              {
                "judge_id": "claude-3-7-sonnet-20250219",
                "metrics": {
                  "novelty_score": 0.4,
                  "relevance_score": 0.2,
                  "reasonableness_score": 1.0
                }
              },
              {
                "judge_id": "gpt-4.1-2025-04-14",
                "metrics": {
                  "novelty_score": 0.2,
                  "relevance_score": 0.2,
                  "reasonableness_score": 1.0
                }
              }
            ],
            "judges_stats": {
              "novelty_score_mean": 0.30000000000000004,
              "novelty_score_variance": 0.010000000000000002,
              "novelty_score_all_values": {
                "claude-3-7-sonnet-20250219": 0.4,
                "gpt-4.1-2025-04-14": 0.2
              },
              "relevance_score_mean": 0.2,
              "relevance_score_variance": 0.0,
              "relevance_score_all_values": {
                "claude-3-7-sonnet-20250219": 0.2,
                "gpt-4.1-2025-04-14": 0.2
              },
              "reasonableness_score_mean": 1.0,
              "reasonableness_score_variance": 0.0,
              "reasonableness_score_all_values": {
                "claude-3-7-sonnet-20250219": 1.0,
                "gpt-4.1-2025-04-14": 1.0
              }
            }
          }
        },
        {
          "statement_id": 8,
          "player_id": 1,
          "llm_id": "claude-3-5-haiku-20241022",
          "content": "Requires electrical power to function effectively in its cleaning role.",
          "statement_round": 2,
          "metrics": {
            "judges_evaluations": [
              {
                "judge_id": "claude-3-7-sonnet-20250219",
                "metrics": {
                  "novelty_score": 0.8,
                  "relevance_score": 0.8,
                  "reasonableness_score": 1.0
                }
              },
              {
                "judge_id": "gpt-4.1-2025-04-14",
                "metrics": {
                  "novelty_score": 0.8,
                  "relevance_score": 0.8,
                  "reasonableness_score": 1.0
                }
              }
            ],
            "judges_stats": {
              "novelty_score_mean": 0.8,
              "novelty_score_variance": 0.0,
              "novelty_score_all_values": {
                "claude-3-7-sonnet-20250219": 0.8,
                "gpt-4.1-2025-04-14": 0.8
              },
              "relevance_score_mean": 0.8,
              "relevance_score_variance": 0.0,
              "relevance_score_all_values": {
                "claude-3-7-sonnet-20250219": 0.8,
                "gpt-4.1-2025-04-14": 0.8
              },
              "reasonableness_score_mean": 1.0,
              "reasonableness_score_variance": 0.0,
              "reasonableness_score_all_values": {
                "claude-3-7-sonnet-20250219": 1.0,
                "gpt-4.1-2025-04-14": 1.0
              }
            }
          }
        },
        {
          "statement_id": 9,
          "player_id": 4,
          "llm_id": "llama-3.3-70b-instruct",
          "content": "It usually has a bag or container to collect the dirt and debris it picks up.",
          "statement_round": 2,
          "metrics": {
            "judges_evaluations": [
              {
                "judge_id": "claude-3-7-sonnet-20250219",
                "metrics": {
                  "novelty_score": 0.8,
                  "relevance_score": 0.8,
                  "reasonableness_score": 1.0
                }
              },
              {
                "judge_id": "gpt-4.1-2025-04-14",
                "metrics": {
                  "novelty_score": 0.8,
                  "relevance_score": 0.8,
                  "reasonableness_score": 1.0
                }
              }
            ],
            "judges_stats": {
              "novelty_score_mean": 0.8,
              "novelty_score_variance": 0.0,
              "novelty_score_all_values": {
                "claude-3-7-sonnet-20250219": 0.8,
                "gpt-4.1-2025-04-14": 0.8
              },
              "relevance_score_mean": 0.8,
              "relevance_score_variance": 0.0,
              "relevance_score_all_values": {
                "claude-3-7-sonnet-20250219": 0.8,
                "gpt-4.1-2025-04-14": 0.8
              },
              "reasonableness_score_mean": 1.0,
              "reasonableness_score_variance": 0.0,
              "reasonableness_score_all_values": {
                "claude-3-7-sonnet-20250219": 1.0,
                "gpt-4.1-2025-04-14": 1.0
              }
            }
          }
        }
      ],
      "voting_rounds": [
        {
          "voting_round_id": 1,
          "after_statement_round": 1,
          "after_statement_id": 6,
          "votes": [
            {
              "voter_id": 1,
              "voted_for": 2
            },
            {
              "voter_id": 2,
              "voted_for": 5
            },
            {
              "voter_id": 4,
              "voted_for": 2
            },
            {
              "voter_id": 5,
              "voted_for": 1
            }
          ],
          "vote_results": {
            "1": 1,
            "2": 2,
            "4": 0,
            "5": 1
          },
          "eliminated": [
            {
              "player_id": 2,
              "llm_id": "gpt-4o-2024-11-20",
              "role": "civilian",
              "correct_elimination": false
            }
          ]
        },
        {
          "voting_round_id": 2,
          "after_statement_round": 2,
          "after_statement_id": 9,
          "votes": [
            {
              "voter_id": 1,
              "voted_for": 4
            },
            {
              "voter_id": 4,
              "voted_for": 5
            },
            {
              "voter_id": 5,
              "voted_for": 1
            }
          ],
          "vote_results": {
            "1": 1,
            "4": 1,
            "5": 1
          },
          "eliminated": [
            {
              "player_id": 4,
              "llm_id": "llama-3.3-70b-instruct",
              "role": "civilian",
              "correct_elimination": false
            }
          ]
        }
      ],
      "metric_eliminations": [
        {
          "player_id": 3,
          "llm_id": "qwen2.5-72b",
          "role": "civilian",
          "elimination_round": 1,
          "elimination_reason": "Low novelty score: 0.20",
          "metrics": {
            "novelty_mean": 0.2,
            "reasonableness_mean": 1.0
          }
        },
        {
          "player_id": 6,
          "llm_id": "deepseek-v3",
          "role": "undercover",
          "elimination_round": 1,
          "elimination_reason": "Low reasonableness score: 0.00",
          "metrics": {
            "novelty_mean": 0.5,
            "reasonableness_mean": 0.0
          }
        }
      ]
    },
    "game_summary": {
      "total_statement_rounds": 2,
      "total_voting_rounds": 2,
      "total_statements": 9,
      "winner_role": "undercover",
      "winner_ids": [
        5,
        6
      ],
      "correct_identifications": 0,
      "incorrect_identifications": 2,
      "game_decision_quality": 0.0
    },
    "game_analysis": {}
  }
}